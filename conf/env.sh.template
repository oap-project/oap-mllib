# == OAP MLlib users to customize the following environments for running examples ======= #

# ============== Minimum Settings ============= #

# Set Spark master, should be spark://xxx or yarn
SPARK_MASTER=spark://localhost:7077
# SPARK_MASTER=yarn

# Set Hadoop home path
export HADOOP_HOME=$HADOOP_HOME
# export HADOOP_HOME=/path/to/your/hadoop/home

# Set Spark home path
export SPARK_HOME=$SPARK_HOME
# export SPARK_HOME=/path/to/your/spark/home

# Set OAP MLlib source code root directory
SCRIPT_DIR=$( cd $(dirname ${BASH_SOURCE[0]}) && pwd )
export OAP_MLLIB_ROOT=$(cd $SCRIPT_DIR/.. && pwd)
# export OAP_MLLIB_ROOT=/path/to/oap-mllib/home

# Set HDFS Root, should be hdfs://xxx or file://xxx
export HDFS_ROOT=file://$OAP_MLLIB_ROOT/examples
# export HDFS_ROOT=hdfs://localhost:8020

# ============================================= #

# Import RELEASE envs
source $OAP_MLLIB_ROOT/RELEASE

# Set HADOOP_CONF_DIR for Spark
export HADOOP_CONF_DIR=$HADOOP_HOME/etc/hadoop

# Set JAR name & path
OAP_MLLIB_JAR_NAME=oap-mllib-$OAP_MLLIB_VERSION.jar
OAP_MLLIB_JAR=$OAP_MLLIB_ROOT/mllib-dal/target/$OAP_MLLIB_JAR_NAME
# Set Spark driver & executor classpaths
# YARN mode: use absolute path for driver, relative path for executors
# Standalone mode: use absolute path for both driver and executors
SPARK_DRIVER_CLASSPATH=$OAP_MLLIB_JAR
if [[ $SPARK_MASTER == yarn ]]; then
  SPARK_EXECUTOR_CLASSPATH=./$OAP_MLLIB_JAR_NAME
else
  SPARK_EXECUTOR_CLASSPATH=$OAP_MLLIB_JAR
fi

# Set Spark resources, can be overwritten in example
SPARK_DRIVER_MEMORY=1G
SPARK_NUM_EXECUTORS=2
SPARK_EXECUTOR_CORES=1
SPARK_EXECUTOR_MEMORY=1G
SPARK_TOTAL_CORES=$((SPARK_NUM_EXECUTORS * SPARK_EXECUTOR_CORES))
SPARK_DEFAULT_PARALLELISM=$((SPARK_TOTAL_CORES * 2))

# Checks
for dir in $SPARK_HOME $HADOOP_HOME $OAP_MLLIB_JAR
do
    if [[ ! -e $dir ]]; then
        echo $dir does not exist!
    exit 1
    fi
done
